{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:28:15.453457Z","iopub.execute_input":"2025-09-30T16:28:15.453731Z","iopub.status.idle":"2025-09-30T16:28:27.692898Z","shell.execute_reply.started":"2025-09-30T16:28:15.453710Z","shell.execute_reply":"2025-09-30T16:28:27.692154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, random, time, glob\nimport numpy as np\nimport tensorflow as tf\n\nprint(\"TensorFlow:\", tf.__version__)\n\nSEED = 1337\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n\ntry:\n    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n    print(\"Mixed precision: ON\")\nexcept Exception as e:\n    print(\"Mixed precision not available:\", e)\n\nDATA_DIR  = \"/kaggle/input/gan-getting-started\"\nPHOTO_JPG = os.path.join(DATA_DIR, \"photo_jpg\")\nMONET_JPG = os.path.join(DATA_DIR, \"monet_jpg\")\n\nIMG_SIZE   = 256\nIMG_SHAPE  = (IMG_SIZE, IMG_SIZE, 3)\nBATCH_SIZE = 4  \n\n\nEPOCHS       = 50\nLR           = 2e-4\nLAMBDA_CYCLE = 10.0\nLAMBDA_ID    = 0.5\n\nAUTO = tf.data.AUTOTUNE\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T19:03:38.785086Z","iopub.execute_input":"2025-09-30T19:03:38.785694Z","iopub.status.idle":"2025-09-30T19:03:39.008213Z","shell.execute_reply.started":"2025-09-30T19:03:38.785670Z","shell.execute_reply":"2025-09-30T19:03:39.007265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def decode_jpg(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)          # RGB\n    img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method=\"area\")\n    return img\n\n@tf.function\ndef augment(img):\n\n    j = IMG_SIZE + 30\n    img = tf.image.resize(img, [j, j], method=\"bilinear\")\n    img = tf.image.random_crop(img, [IMG_SIZE, IMG_SIZE, 3])\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_brightness(img, max_delta=0.05)\n    img = tf.image.random_contrast(img, lower=0.9, upper=1.1)\n    return img\n\n@tf.function\ndef to_m11(img): \n    return img * 2.0 - 1.0\n\ndef load_jpg_dataset(folder, training=True):\n    files = tf.io.gfile.glob(os.path.join(folder, \"*.jpg\"))\n    files.sort()\n    ds = tf.data.Dataset.from_tensor_slices(files)\n    if training:\n        ds = ds.shuffle(len(files), seed=SEED, reshuffle_each_iteration=True)\n    ds = ds.map(decode_jpg, num_parallel_calls=AUTO)\n    if training:\n        ds = ds.map(augment, num_parallel_calls=AUTO)\n    ds = ds.map(to_m11, num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH_SIZE, drop_remainder=training)  \n    ds = ds.prefetch(AUTO)\n    return ds\n\n\nphoto_ds = load_jpg_dataset(PHOTO_JPG, training=True)\nmonet_ds = load_jpg_dataset(MONET_JPG, training=True)\n\nprint(\"photo_ds batches:\", tf.data.experimental.cardinality(photo_ds).numpy())\nprint(\"monet_ds batches:\", tf.data.experimental.cardinality(monet_ds).numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T19:03:42.333520Z","iopub.execute_input":"2025-09-30T19:03:42.334256Z","iopub.status.idle":"2025-09-30T19:03:44.774732Z","shell.execute_reply.started":"2025-09-30T19:03:42.334231Z","shell.execute_reply":"2025-09-30T19:03:44.774137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom tensorflow.keras import layers as KL, Model\n\nclass InstanceNorm(KL.Layer):\n    def __init__(self, eps=1e-5):\n        super().__init__(); self.eps = eps\n    def build(self, s):\n        ch = s[-1]\n        self.gamma = self.add_weight(shape=(ch,), initializer=\"ones\",  trainable=True)\n        self.beta  = self.add_weight(shape=(ch,), initializer=\"zeros\", trainable=True)\n    def call(self, x):\n        m, v = tf.nn.moments(x, axes=[1,2], keepdims=True)\n        return self.gamma * (x - m) / tf.sqrt(v + self.eps) + self.beta\n\ndef conv7(x, f):\n    x = KL.Conv2D(f, 7, padding=\"same\", use_bias=False)(x)\n    x = InstanceNorm()(x)\n    return KL.Activation(\"relu\")(x)\n\ndef down(x, f):\n    x = KL.Conv2D(f, 3, strides=2, padding=\"same\", use_bias=False)(x)\n    x = InstanceNorm()(x)\n    return KL.Activation(\"relu\")(x)\n\ndef resblock(x, f):\n    y = KL.Conv2D(f, 3, padding=\"same\", use_bias=False)(x)\n    y = InstanceNorm()(y); y = KL.Activation(\"relu\")(y)\n    y = KL.Conv2D(f, 3, padding=\"same\", use_bias=False)(y)\n    y = InstanceNorm()(y)\n    return KL.Add()([x, y])\n\ndef up(x, f):\n    x = KL.Conv2DTranspose(f, 3, strides=2, padding=\"same\", use_bias=False)(x)\n    x = InstanceNorm()(x)\n    return KL.Activation(\"relu\")(x)\n\ndef build_generator(img_shape=IMG_SHAPE, n_res=9):\n    inp = KL.Input(img_shape)\n    x = conv7(inp, 64)\n    x = down(x, 128); x = down(x, 256)\n    for _ in range(n_res): x = resblock(x, 256)\n    x = up(x, 128); x = up(x, 64)\n    x = KL.Conv2D(3, 7, padding=\"same\")(x)\n    x = KL.Activation(\"tanh\")(x)                              \n    out = KL.Lambda(lambda t: tf.cast(t, tf.float32))(x)      \n    return Model(inp, out, name=\"Generator\")\n\ndef build_discriminator(img_shape=IMG_SHAPE):\n    def blk(x, f, s, norm=True):\n        x = KL.Conv2D(f, 4, strides=s, padding=\"same\", use_bias=not norm)(x)\n        if norm: x = InstanceNorm()(x)\n        return KL.LeakyReLU(0.2)(x)\n    inp = KL.Input(img_shape)\n    x = blk(inp,  64, 2, norm=False)\n    x = blk(x,   128, 2)\n    x = blk(x,   256, 2)\n    x = blk(x,   512, 1)\n    out = KL.Conv2D(1, 4, padding=\"same\")(x)  \n    return Model(inp, out, name=\"Discriminator\")\n\n# 2x Generatory i 2x Dyskryminatory\nG_p2m = build_generator()    \nG_m2p = build_generator()     \nD_m   = build_discriminator() \nD_p   = build_discriminator() \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T19:04:19.514036Z","iopub.execute_input":"2025-09-30T19:04:19.514577Z","iopub.status.idle":"2025-09-30T19:04:20.745722Z","shell.execute_reply.started":"2025-09-30T19:04:19.514556Z","shell.execute_reply":"2025-09-30T19:04:20.744948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mse = tf.keras.losses.MeanSquaredError()\nmae = tf.keras.losses.MeanAbsoluteError()\n\ndef gen_gan_loss(d_fake):\n  \n    return mse(tf.ones_like(d_fake), d_fake)\n\ndef disc_loss(d_real, d_fake):\n   \n    loss_real = mse(tf.ones_like(d_real), d_real)\n    loss_fake = mse(tf.zeros_like(d_fake), d_fake)\n    return 0.5 * (loss_real + loss_fake)\n\nopt_G  = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.999)\nopt_Dm = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.999)\nopt_Dp = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.999)\n\nCKPT_DIR = os.path.join(\"/kaggle/working\", \"ckpts\")\nckpt = tf.train.Checkpoint(\n    G_p2m=G_p2m, G_m2p=G_m2p, D_m=D_m, D_p=D_p,\n    opt_G=opt_G, opt_Dm=opt_Dm, opt_Dp=opt_Dp\n)\nckpt_manager = tf.train.CheckpointManager(ckpt, directory=CKPT_DIR, max_to_keep=3)\n\nlatest = ckpt_manager.latest_checkpoint\nif latest:\n    print(f\"Przywracam checkpoint: {latest}\")\n    ckpt.restore(latest)\nelse:\n    print(\"Brak istniejących checkpointów — start od zera.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T19:04:27.860165Z","iopub.execute_input":"2025-09-30T19:04:27.860837Z","iopub.status.idle":"2025-09-30T19:04:28.131980Z","shell.execute_reply.started":"2025-09-30T19:04:27.860812Z","shell.execute_reply":"2025-09-30T19:04:28.131389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% ETAP 4 — train_step \n@tf.function\ndef train_step(batch_photo, batch_monet):\n    with tf.GradientTape(persistent=True) as tape:\n     \n        fake_monet = G_p2m(batch_photo, training=True)\n        fake_photo = G_m2p(batch_monet, training=True)\n\n        \n        rec_photo = G_m2p(fake_monet, training=True)  \n        rec_monet = G_p2m(fake_photo, training=True)  \n\n       \n        id_monet = G_p2m(batch_monet, training=True)\n        id_photo = G_m2p(batch_photo, training=True)\n\n        \n        d_m_real = D_m(batch_monet, training=True)\n        d_m_fake = D_m(fake_monet, training=True)\n        d_p_real = D_p(batch_photo, training=True)\n        d_p_fake = D_p(fake_photo, training=True)\n\n        \n        g_adv_p2m = gen_gan_loss(d_m_fake)\n        g_adv_m2p = gen_gan_loss(d_p_fake)\n        cycle     = (mae(batch_photo, rec_photo) + mae(batch_monet, rec_monet)) * LAMBDA_CYCLE\n        ident     = (mae(batch_monet, id_monet) + mae(batch_photo, id_photo)) * (LAMBDA_CYCLE * LAMBDA_ID)\n        g_total   = g_adv_p2m + g_adv_m2p + cycle + ident\n\n       \n        d_m = disc_loss(d_m_real, d_m_fake)\n        d_p = disc_loss(d_p_real, d_p_fake)\n\n    vars_G = G_p2m.trainable_variables + G_m2p.trainable_variables\n    opt_G.apply_gradients(zip(tape.gradient(g_total, vars_G), vars_G))\n    opt_Dm.apply_gradients(zip(tape.gradient(d_m, D_m.trainable_variables), D_m.trainable_variables))\n    opt_Dp.apply_gradients(zip(tape.gradient(d_p, D_p.trainable_variables), D_p.trainable_variables))\n\n    return {\"g_total\": g_total, \"cycle\": cycle, \"id\": ident, \"d_m\": d_m, \"d_p\": d_p}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T19:04:41.666875Z","iopub.execute_input":"2025-09-30T19:04:41.667573Z","iopub.status.idle":"2025-09-30T19:04:41.756360Z","shell.execute_reply.started":"2025-09-30T19:04:41.667552Z","shell.execute_reply":"2025-09-30T19:04:41.755550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% ETAP 5 — trening: \nLOG_EVERY = 200  \n\nif 'photo_ds' not in globals() or 'monet_ds' not in globals():\n    raise RuntimeError(\"Brak datasetów: uruchom wcześniej ETAP 1.\")\nif 'train_step' not in globals():\n    raise RuntimeError(\"Brak train_step: uruchom wcześniej ETAP 4.\")\n\nglobal_step = 0\nfor epoch in range(1, EPOCHS + 1):\n    t0 = time.time()\n\n\n    zipped = tf.data.Dataset.zip((photo_ds, monet_ds)).prefetch(AUTO)\n\n    for step, (photos, monets) in enumerate(zipped, start=1):\n        logs = train_step(photos, monets)\n        global_step += 1\n\n        if global_step % LOG_EVERY == 0:\n            print(\n                f\"[ep {epoch:02d} | step {global_step:05d}] \"\n                f\"G_total:{float(logs['g_total']):.3f}  \"\n                f\"cycle:{float(logs['cycle']):.3f}  id:{float(logs['id']):.3f}  \"\n                f\"Dm:{float(logs['d_m']):.3f}  Dp:{float(logs['d_p']):.3f}\"\n            )\n\n    ckpt_manager.save()\n    print(f\"Epoch {epoch} done in {time.time()-t0:.1f}s  |  checkpoint: {ckpt_manager.latest_checkpoint}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T19:04:45.891478Z","iopub.execute_input":"2025-09-30T19:04:45.892035Z","iopub.status.idle":"2025-09-30T20:37:36.965737Z","shell.execute_reply.started":"2025-09-30T19:04:45.891997Z","shell.execute_reply":"2025-09-30T20:37:36.965049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, tensorflow as tf\nfrom tensorflow.keras import layers as KL, Model\n\nIMG_SIZE  = 256\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\nLR = 2e-4 \n\nclass InstanceNorm(KL.Layer):\n    def __init__(self, eps=1e-5): super().__init__(); self.eps = eps\n    def build(self, s):\n        ch = s[-1]\n        self.gamma = self.add_weight(shape=(ch,), initializer=\"ones\",  trainable=True)\n        self.beta  = self.add_weight(shape=(ch,), initializer=\"zeros\", trainable=True)\n    def call(self, x):\n        m, v = tf.nn.moments(x, axes=[1,2], keepdims=True)\n        return self.gamma * (x - m) / tf.sqrt(v + self.eps) + self.beta\n\ndef conv7(x, f):\n    x = KL.Conv2D(f, 7, padding=\"same\", use_bias=False)(x)\n    x = InstanceNorm()(x)\n    return KL.Activation(\"relu\")(x)\n\ndef down(x, f):\n    x = KL.Conv2D(f, 3, strides=2, padding=\"same\", use_bias=False)(x)\n    x = InstanceNorm()(x)\n    return KL.Activation(\"relu\")(x)\n\ndef resblock(x, f):\n    y = KL.Conv2D(f, 3, padding=\"same\", use_bias=False)(x)\n    y = InstanceNorm()(y); y = KL.Activation(\"relu\")(y)\n    y = KL.Conv2D(f, 3, padding=\"same\", use_bias=False)(y)\n    y = InstanceNorm()(y)\n    return KL.Add()([x, y])\n\ndef up(x, f):\n    x = KL.Conv2DTranspose(f, 3, strides=2, padding=\"same\", use_bias=False)(x)\n    x = InstanceNorm()(x)\n    return KL.Activation(\"relu\")(x)\n\ndef build_generator(img_shape=IMG_SHAPE, n_res=9):\n    inp = KL.Input(img_shape)\n    x = conv7(inp, 64)\n    x = down(x, 128); x = down(x, 256)\n    for _ in range(n_res): x = resblock(x, 256)\n    x = up(x, 128); x = up(x, 64)\n    x = KL.Conv2D(3, 7, padding=\"same\")(x)\n    x = KL.Activation(\"tanh\")(x)                   \n    out = KL.Lambda(lambda t: tf.cast(t, tf.float32))(x)\n    return Model(inp, out, name=\"Generator\")\n\ndef build_discriminator(img_shape=IMG_SHAPE):\n    def blk(x, f, s, norm=True):\n        x = KL.Conv2D(f, 4, strides=s, padding=\"same\", use_bias=not norm)(x)\n        if norm: x = InstanceNorm()(x)\n        return KL.LeakyReLU(0.2)(x)\n    inp = KL.Input(img_shape)\n    x = blk(inp,  64, 2, norm=False)\n    x = blk(x,   128, 2)\n    x = blk(x,   256, 2)\n    x = blk(x,   512, 1)\n    out = KL.Conv2D(1, 4, padding=\"same\")(x)\n    return Model(inp, out, name=\"Discriminator\")\n\nG_p2m = build_generator()    \nG_m2p = build_generator()     \nD_m   = build_discriminator()\nD_p   = build_discriminator()\n\nopt_G  = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.999)\nopt_Dm = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.999)\nopt_Dp = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.999)\n\nCKPT_DIR = \"/kaggle/working/ckpts\"\nckpt = tf.train.Checkpoint(G_p2m=G_p2m, G_m2p=G_m2p, D_m=D_m, D_p=D_p,\n                           opt_G=opt_G, opt_Dm=opt_Dm, opt_Dp=opt_Dp)\nckpt_manager = tf.train.CheckpointManager(ckpt, directory=CKPT_DIR, max_to_keep=3)\n\nif ckpt_manager.latest_checkpoint:\n    ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n    print(\"Przywrócono:\", ckpt_manager.latest_checkpoint)\nelse:\n    raise RuntimeError(\"Nie znaleziono checkpointów w /kaggle/working/ckpts — uruchom ponownie trening (ETAP 5).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T20:41:19.396477Z","iopub.execute_input":"2025-09-30T20:41:19.396764Z","iopub.status.idle":"2025-09-30T20:41:20.861365Z","shell.execute_reply.started":"2025-09-30T20:41:19.396744Z","shell.execute_reply":"2025-09-30T20:41:20.860654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, zipfile\nimport tensorflow as tf\n\nPHOTO_JPG = \"/kaggle/input/gan-getting-started/photo_jpg\"\n\ndef load_jpg_dataset_infer(folder, batch_size=4):\n    files = tf.io.gfile.glob(os.path.join(folder, \"*.jpg\"))\n    files.sort()\n    ds = tf.data.Dataset.from_tensor_slices(files)\n    \n    def decode_norm(p):\n        img = tf.io.read_file(p)\n        img = tf.image.decode_jpeg(img, channels=3)\n        img = tf.image.resize(img, [256, 256])\n        img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]\n        return img * 2.0 - 1.0                                # [-1,1]\n    \n    ds = ds.map(decode_norm, num_parallel_calls=tf.data.AUTOTUNE)\n    ds = ds.batch(batch_size, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n    return ds\n\nphoto_ds_infer = load_jpg_dataset_infer(PHOTO_JPG, batch_size=4)\n\ndef encode_jpeg_uint8(img_m11):\n    img = (img_m11 + 1.0) / 2.0 \n    img = tf.clip_by_value(img, 0.0, 1.0)\n    img = tf.image.convert_image_dtype(img, tf.uint8)\n    return tf.io.encode_jpeg(img, format='rgb', quality=95)\n\ndef generate_to_zip(generator, dataset, target_count, zip_path):\n    written = 0\n    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_STORED) as zf:\n        for batch in dataset:\n            fakes = generator(batch, training=False)\n            for i in range(fakes.shape[0]):\n                if written >= target_count: break\n                img_bytes = encode_jpeg_uint8(fakes[i]).numpy()\n                zf.writestr(f\"image_{written:06d}.jpg\", img_bytes)\n                written += 1\n            if written >= target_count: break\n        \n        if written < target_count:\n            print(f\"Dogenerowuję {target_count - written} obrazów z lekką augmentacją…\")\n            for batch in dataset:\n                imgs = (batch + 1.0) / 2.0  # [0,1]\n                imgs = tf.image.random_flip_left_right(imgs)\n                imgs = tf.image.random_brightness(imgs, max_delta=0.05)\n                imgs = tf.image.random_contrast(imgs, 0.95, 1.05)\n                imgs = tf.clip_by_value(imgs, 0.0, 1.0)\n                imgs = imgs * 2.0 - 1.0  # z powrotem [-1,1]\n                fakes = generator(imgs, training=False)\n                for i in range(fakes.shape[0]):\n                    if written >= target_count: break\n                    img_bytes = encode_jpeg_uint8(fakes[i]).numpy()\n                    zf.writestr(f\"image_{written:06d}.jpg\", img_bytes)\n                    written += 1\n                if written >= target_count: break\n    return written\n\nTARGET_COUNT = 9500\nZIP_PATH = \"/kaggle/working/images.zip\"\n\ngenerated_count = generate_to_zip(G_p2m, photo_ds_infer, TARGET_COUNT, ZIP_PATH)\nprint(f\"✅ Zapisano {generated_count} obrazów do: {ZIP_PATH}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T20:41:26.026786Z","iopub.execute_input":"2025-09-30T20:41:26.027523Z","iopub.status.idle":"2025-09-30T20:45:24.070042Z","shell.execute_reply.started":"2025-09-30T20:41:26.027499Z","shell.execute_reply":"2025-09-30T20:45:24.069208Z"}},"outputs":[],"execution_count":null}]}